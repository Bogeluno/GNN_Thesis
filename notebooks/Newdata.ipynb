{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import glob\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import rtree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "files = glob.glob(\"data/raw/SNData/*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for f in tqdm.tqdm(files):\n",
    "    dfs.append(pd.read_csv(f, header=0, sep=\";\"))\n",
    "\n",
    "Full_data = pd.concat(dfs,ignore_index=True) # Save this to interim\n",
    "Full_data.to_csv('data/interim/Full_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop 53 rows with na values\n",
    "df = Full_data.dropna()\n",
    "\n",
    "# Rename Columns to English\n",
    "df. columns = ['Customer_Group', 'CustomerID', 'CarID', 'Engine', 'Rental_flag', 'RentalID', 'Rental_Usage_Type', 'Reservation_Time', 'End_Time', 'Revenue', 'Distance', 'Drives', 'Reservation_Minutes','Fuel_Start','Fuel_End','Start_Lat', 'Start_Long', 'End_Lat', 'End_Long']\n",
    "\n",
    "# Fix type\n",
    "df = df.astype({'CustomerID': 'int32', 'RentalID': 'int64'})\n",
    "\n",
    "# Drop drives as it has no info (only ones)\n",
    "df.drop(columns = 'Drives', inplace=True)\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove all rows with a CarID as it can not be used\n",
    "df = df[df.CarID != '0']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Engine has two types of missing values that is alligned\n",
    "df[\"Engine\"].replace({\" \": '0'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If a CarID already has an engine type assign that to the missing ones\n",
    "Engine_dict = {c: df[df.CarID == c].Engine.nunique() for c in df[df.Engine == '0'].CarID.unique()}\n",
    "for car, engine in Engine_dict.items():\n",
    "    if engine == 1:\n",
    "        continue\n",
    "    True_Engine = [x for x in df[df.CarID == car].Engine.unique() if x!= '0'][0]\n",
    "    df.loc[(df.CarID == car) & (df.Engine == '0'), 'Engine'] = True_Engine\n",
    "\n",
    "# Populate the rest manual based on ID\n",
    "df.loc[(df.CarID == 'WBA1R5104J7B14310') & (df.Engine == '0'), 'Engine'] = '118I'\n",
    "df.loc[(df.CarID == 'WBA1R5104J5K58061') & (df.Engine == '0'), 'Engine'] = '118I'\n",
    "df.loc[(df.CarID == 'WBA1R5103K7D66678') & (df.Engine == '0'), 'Engine'] = '118I'\n",
    "df.loc[(df.CarID == 'WBY8P2105K7D70350') & (df.Engine == '0'), 'Engine'] = 'I3 120'\n",
    "df.loc[(df.CarID == 'WBY8P2102K7D70287') & (df.Engine == '0'), 'Engine'] = 'I3 120'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Times"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df['Reservation_Time'] = pd.to_datetime(df['Reservation_Time'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], format=\"%d.%m.%Y %H:%M:%S\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix trips where same user use same car"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split data on Car level\n",
    "CarID_dict = dict(iter(df.groupby('CarID')))\n",
    "\n",
    "def fix_merges(dataframe, max_time_diff = 60):\n",
    "    dataframe = dataframe.sort_values(by = 'Reservation_Time')\n",
    "    # Get index where same customer uses the same car back to back\n",
    "    diff0_iloc = [dataframe.index.get_loc(x) for x in dataframe.index[(dataframe.CustomerID.diff() == 0).tolist()]]\n",
    "\n",
    "    # Find paris to be merged\n",
    "    merge_pairs = [(idx-1,idx) for idx in diff0_iloc if dataframe.iloc[idx-1].End_Time+pd.to_timedelta(max_time_diff+dataframe.iloc[idx].Reservation_Minutes,'m') > dataframe.iloc[idx].Reservation_Time]\n",
    "\n",
    "    # Model as graph to get cc\n",
    "    graph_model = nx.Graph(merge_pairs)\n",
    "    groups = [(min(cc),max(cc)) for cc in list(nx.connected_components(graph_model))]\n",
    "\n",
    "    # Populate \n",
    "    for pair in groups:\n",
    "        dataframe.loc[dataframe.index[pair[0]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']] = dataframe.loc[dataframe.index[pair[1]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']]\n",
    "\n",
    "\n",
    "    # Delete now unwanted rows\n",
    "    rows_to_delete = [x[1] for x in merge_pairs]\n",
    "    dataframe.drop(index = [dataframe.index[x] for x in rows_to_delete], inplace = True)\n",
    "\n",
    "    # Return fixed dataframe\n",
    "    return dataframe\n",
    "\n",
    "# Merge new datasets\n",
    "dfs = []\n",
    "for sub_df in tqdm.tqdm(CarID_dict.values()):\n",
    "    dfs.append(fix_merges(sub_df))\n",
    "\n",
    "df = pd.concat(dfs,ignore_index=False).sort_values(by = 'RentalID')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.to_csv('data/interim/first_version.csv')\n",
    "df.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import glob\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import rtree\n",
    "\n",
    "df = pd.read_csv('data/interim/first_version.csv', index_col = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df['Reservation_Time'] = pd.to_datetime(df['Reservation_Time'], format=\"%Y.%m.%d %H:%M:%S\")\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], format=\"%Y.%m.%d %H:%M:%S\")\n",
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2439290 entries, 1969578 to 1457879\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   Customer_Group       object        \n",
      " 1   CustomerID           int64         \n",
      " 2   CarID                object        \n",
      " 3   Engine               object        \n",
      " 4   Rental_flag          object        \n",
      " 5   RentalID             int64         \n",
      " 6   Rental_Usage_Type    object        \n",
      " 7   Reservation_Time     datetime64[ns]\n",
      " 8   End_Time             datetime64[ns]\n",
      " 9   Revenue              float64       \n",
      " 10  Distance             int64         \n",
      " 11  Reservation_Minutes  int64         \n",
      " 12  Fuel_Start           int64         \n",
      " 13  Fuel_End             int64         \n",
      " 14  Start_Lat            float64       \n",
      " 15  Start_Long           float64       \n",
      " 16  End_Lat              float64       \n",
      " 17  End_Long             float64       \n",
      "dtypes: datetime64[ns](2), float64(5), int64(6), object(5)\n",
      "memory usage: 353.6+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix 0,0 locations\n",
    "\n",
    "We also accept the other ones outside Copenhagen as the cars must have been there. They can be removed in the vacancy dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, row in df[(df.Start_Lat < 5)].iterrows():\n",
    "    # Skip if first instance as it will unaffect vacancy\n",
    "    sub_df = df[df.CarID == row.CarID].sort_values('RentalID')\n",
    "    err_index = sub_df.index.get_loc(i)\n",
    "    if err_index == 0:\n",
    "        continue\n",
    "\n",
    "    # Populate based on previous end \n",
    "    df.loc[i, ['Start_Lat', 'Start_Long']] = sub_df.iloc[err_index-1].loc[['End_Lat','End_Long']].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, row in df[(df.End_Lat < 5)].iterrows():\n",
    "    sub_df = df[df.CarID == row.CarID].sort_values('RentalID')\n",
    "    err_index = sub_df.index.get_loc(i)\n",
    "\n",
    "    # Will fail if last index\n",
    "    try:\n",
    "        df.loc[i, ['End_Lat', 'End_Long']] = sub_df.iloc[err_index+1].loc[['Start_Lat','Start_Long']].values\n",
    "    except:\n",
    "        continue\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add zones"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load shapefile and set projection\n",
    "shapefile = gpd.read_file(\"../Zonekort/LTM_Zone3/zones_level3.shp\")\n",
    "shapefile = shapefile.to_crs(epsg=4326)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a geoDF with geometry as starting point\n",
    "gdf_start = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.Start_Long, df.Start_Lat))\n",
    "\n",
    "# Set projection\n",
    "gdf_start = gdf_start.set_crs(epsg=4326)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Populate zones based on which zone they are within\n",
    "gdpj_start  = gpd.sjoin(gdf_start, shapefile, op='within')\n",
    "df['Start_Zone'] = gdpj_start.zoneid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Populate the rest based on which zone they are closest too\n",
    "Start_zone_filler = {x: shapefile.zoneid[shapefile.distance(df.loc[x].geometry).sort_values().index[0]] for x in df.index[df['Start_Zone'].isna()]}\n",
    "df['Start_Zone'] = df['Start_Zone'].fillna(Start_zone_filler)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a geoDF with geometry as end point\n",
    "gdf_end = gpd.GeoDataFrame(df, geometry= gpd.points_from_xy(df.End_Long, df.End_Lat))\n",
    "\n",
    "# Set projection\n",
    "gdf_end = gdf_end.set_crs(epsg=4326)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Populate zones based on which zone they are within\n",
    "gdpj_end  = gpd.sjoin(gdf_end, shapefile, op='within')\n",
    "df['End_Zone'] = gdpj_end.zoneid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Populate the rest based on which zone they are closest too\n",
    "End_zone_filler = {x: shapefile.zoneid[shapefile.distance(df.loc[x].geometry).sort_values().index[0]] for x in df.index[df['End_Zone'].isna()]}\n",
    "df['End_Zone'] = df['End_Zone'].fillna(End_zone_filler)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove geomery type and make IDs int columns\n",
    "df.drop(columns = 'geometry', inplace = True)\n",
    "df = df.astype({'CustomerID': 'int32', 'RentalID': 'int64', 'Start_Zone': 'int32','End_Zone': 'int32'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check types\n",
    "df.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Sweden and Bornholm\n",
    "#df[df.Start_Long > 13].sort_values(by = 'Reservation_Time')\n",
    "\n",
    "# Jutland\n",
    "#df[(df.Start_Long < 11) & (df.Start_Long > 0) & (df.Customer_Group == 'Customer')]\n",
    "\n",
    "# Car in Germany in the middle of the data..\n",
    "#df[df.CarID == 'WBY1Z21040V308181'].sort_values(by = 'Reservation_Time').iloc[-30:-20]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weird times"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Winter Time\n",
    "WinterTimeIndex = df[(df.Reservation_Time > df.End_Time) & (df.End_Time.apply(lambda x: x.month) == 10) & (df.End_Time.apply(lambda x: x.hour) < 4)].index\n",
    "WinterTimeIndexBack = [2179859, 1683947, 1683948]\n",
    "WinterTimeIndexForward = [x for x in WinterTimeIndex if x not in WinterTimeIndexBack]\n",
    "df.loc[WinterTimeIndexBack, 'Reservation_Time'] = df.loc[WinterTimeIndexBack, 'Reservation_Time'] - pd.to_timedelta(1,'h')\n",
    "df.loc[WinterTimeIndexForward, 'End_Time'] = df.loc[WinterTimeIndexForward, 'End_Time'] + pd.to_timedelta(1,'h')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Remove remaining 50 observations as they will not introduce more vacancy time\n",
    "df.drop(index = df[df.Reservation_Time > df.End_Time].index, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge Non_Customer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Split data on Car level\n",
    "CarID_dict = dict(iter(df.groupby('CarID')))\n",
    "\n",
    "def merge_NC(dataframe, max_time_diff = 60):\n",
    "    dataframe = dataframe.sort_values(by = 'Reservation_Time')\n",
    "    # Get index where non_customer\n",
    "    is_NC = dataframe.Customer_Group == 'Non_Customer'\n",
    "\n",
    "    # Find paris to be merged\n",
    "    merge_pairs = [(is_NC.index.get_loc(k1),is_NC.index.get_loc(k2)) for (k1, v1),(k2,v2) in zip(is_NC.iloc[:-1].iteritems(),is_NC.iloc[1:].iteritems()) if v1&v2]\n",
    "\n",
    "    # Model as graph to get cc\n",
    "    graph_model = nx.Graph(merge_pairs)\n",
    "    groups = [(min(cc),max(cc)) for cc in list(nx.connected_components(graph_model))]\n",
    "\n",
    "    # Populate \n",
    "    for pair in groups:\n",
    "        dataframe.loc[dataframe.index[pair[0]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']] = dataframe.loc[dataframe.index[pair[1]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']]\n",
    "\n",
    "    # Delete now unwanted rows\n",
    "    rows_to_delete = [x[1] for x in merge_pairs]\n",
    "    dataframe.drop(index = [dataframe.index[x] for x in rows_to_delete], inplace = True)\n",
    "\n",
    "    # Return fixed dataframe\n",
    "    return dataframe\n",
    "\n",
    "# Merge new datasets\n",
    "dfs = []\n",
    "for sub_df in tqdm.tqdm(CarID_dict.values()):\n",
    "    dfs.append(merge_NC(sub_df))\n",
    "\n",
    "df = pd.concat(dfs,ignore_index=False).sort_values(by = 'RentalID')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1021/1021 [00:38<00:00, 26.76it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix Overlap"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "CarID_dict = dict(iter(df.groupby('CarID')))\n",
    "tat = []\n",
    "endtat0 = []\n",
    "endtat1 = []\n",
    "endtat2 = []\n",
    "endtat3 = []\n",
    "\n",
    "for car,dataf in CarID_dict.items():\n",
    "    dataf = dataf.sort_values(by = 'Reservation_Time')\n",
    "    tap = list( zip( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]].Customer_Group.values, dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]+1].Customer_Group.values ) )\n",
    "    tat.extend( tap )\n",
    "    if (('Customer', 'Customer') in tap):\n",
    "        print(car)\n",
    "\n",
    "    endtat0.extend( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]].index )\n",
    "    endtat1.extend( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]].Customer_Group )\n",
    "    endtat2.extend( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]+1].Customer_Group )\n",
    "    endtat3.extend( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]].End_Lat )\n",
    "\n",
    "#pd.Series(tat).value_counts()\n",
    "overlap_df = pd.DataFrame(data=[endtat0,endtat1,endtat2,endtat3]).T"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WBA1R5103J7B14248\n",
      "WBA1R5106J7B13384\n",
      "WBY1Z21000V308047\n",
      "WBY1Z21000V308226\n",
      "WBY1Z21010V307912\n",
      "WBY1Z21010V308090\n",
      "WBY1Z21010V308218\n",
      "WBY1Z21010V308221\n",
      "WBY1Z21020V308079\n",
      "WBY1Z21020V308132\n",
      "WBY1Z21020V308258\n",
      "WBY1Z21030V308141\n",
      "WBY1Z21040V307774\n",
      "WBY1Z21040V308035\n",
      "WBY1Z21050V308075\n",
      "WBY1Z21050V308092\n",
      "WBY1Z21060V307937\n",
      "WBY1Z21070V307963\n",
      "WBY1Z21080V307941\n",
      "WBY1Z21090V307852\n",
      "WBY1Z210X0V308010\n",
      "WBY1Z6100HV939142\n",
      "WBY8P2109K7D95235\n",
      "WMWXR3102KTK54716\n",
      "WMWXR3108KTK54607\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Non_Customer, Customer)    169\n",
       "(Customer, Customer)         26\n",
       "(Customer, Non_Customer)     25\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Fix those with bad end_loc\n",
    "fix_idx0 = overlap_df[(overlap_df[1] == 'Customer') & (overlap_df[3] < 1)][0].values\n",
    "df.loc[fix_idx0, 'End_Time'] = df.loc[fix_idx0, 'Reservation_Time'].values + pd.to_timedelta(1,'m')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Fix the other C-C to average of the two reservation times\n",
    "fix_idxP = overlap_df[(overlap_df[1] == 'Customer') & (overlap_df[3] > 1)][0].values\n",
    "# Haversine function\n",
    "def haversine(point1, point2):\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(np.radians, point1)\n",
    "    lat2, lon2 = map(np.radians, point2)\n",
    "\n",
    "    # Deltas\n",
    "    delta_lon = lon2 - lon1 \n",
    "    delta_lat = lat2 - lat1 \n",
    "    \n",
    "    # haversine formula \n",
    "    a = np.sin(delta_lat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in m\n",
    "    return c * r\n",
    "    \n",
    "for fix_idx in fix_idxP:\n",
    "    # Get sub_df\n",
    "    tmp_car_df = df[df.CarID == df.loc[fix_idx].CarID]\n",
    "    \n",
    "    # Get iloc in sub_df of to be fixed\n",
    "    fix_iloc = tmp_car_df.index.get_loc(fix_idx)\n",
    "\n",
    "    # Get end loc of curent and start of next\n",
    "    end_loc = tmp_car_df.loc[fix_idx, ['End_Lat', 'End_Long']].values\n",
    "    start_loc = tmp_car_df.loc[tmp_car_df.index[fix_iloc+1], ['Start_Lat', 'Start_Long']].values\n",
    "\n",
    "    # If parked at same palce adjust\n",
    "    if haversine(end_loc, start_loc) < 100:\n",
    "        avg_time = df.loc[fix_idx,'Reservation_Time'] + (df.loc[tmp_car_df.index[fix_iloc+1],'Reservation_Time'] - df.loc[fix_idx,'Reservation_Time']) / 2\n",
    "        df.loc[fix_idx,'End_Time'] = avg_time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Manual fixes/guestimates\n",
    "df.loc[51903,'End_Time'] = pd.Timestamp(\"2016-11-03 20:00:00\")\n",
    "df.loc[661452,'End_Time'] = pd.Timestamp(\"2017-12-01 17:00:00\")\n",
    "df.loc[52806,'End_Time'] = pd.Timestamp(\"2016-11-05 08:00:10\")\n",
    "df.loc[2376045,'Reservation_Time'] = pd.Timestamp(\"2016-08-05 12:49:38\")\n",
    "df.loc[661513,'End_Time'] = pd.Timestamp(\"2017-12-02 16:16:24\")\n",
    "df.loc[784104,'End_Time'] = pd.Timestamp(\"2017-10-04 12:20:10\")\n",
    "\n",
    "df.drop(index = [22088, 25828, 809192, 664080, 1137264, 713741, 1604116, 2470015, 404202, 661521, 404308], inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "fix_idxCNC = overlap_df[(overlap_df[1]=='Customer') & (overlap_df[2]=='Non_Customer')][0].values\n",
    "for fix_idx in fix_idxCNC:\n",
    "    # Get sub_df\n",
    "    tmp_car_df = df[df.CarID == df.loc[fix_idx].CarID]\n",
    "    \n",
    "    # Get iloc in sub_df of to be fixed\n",
    "    fix_iloc = tmp_car_df.index.get_loc(fix_idx)\n",
    "\n",
    "    # Replace values\n",
    "    df.loc[fix_idx,['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']] = df.loc[tmp_car_df.index[fix_iloc+1],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']]\n",
    "\n",
    "    # Dtop the old NC row\n",
    "    df.drop(tmp_car_df.index[fix_iloc+1], inplace = True)\n",
    "\n",
    "df.drop(index = 888104, inplace = True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "fix_idx_NC0 = overlap_df[(overlap_df[1] ==  'Non_Customer') & (overlap_df[3] < 1)][0].values\n",
    "to_drop = []\n",
    "\n",
    "for fix_idx in fix_idx_NC0:\n",
    "    # Get sub_df\n",
    "    try:\n",
    "        tmp_car_df = df[df.CarID == df.loc[fix_idx].CarID].sort_values(by = 'Reservation_Time')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Get iloc in sub_df of to be fixed\n",
    "    fix_iloc = tmp_car_df.index.get_loc(fix_idx)\n",
    "\n",
    "    # Get the two start locs\n",
    "    start_loc0 = tmp_car_df.loc[tmp_car_df.index[fix_iloc-1], ['Start_Lat', 'Start_Long']].values\n",
    "    start_loc1 = tmp_car_df.loc[fix_idx, ['Start_Lat', 'Start_Long']].values\n",
    "    start_loc2 = tmp_car_df.loc[tmp_car_df.index[fix_iloc+1], ['Start_Lat', 'Start_Long']].values\n",
    "\n",
    "    # If left same spot then drop\n",
    "    if haversine(start_loc0, start_loc1) < 100:\n",
    "        to_drop.append(fix_idx)\n",
    "    if haversine(start_loc1, start_loc2) < 100:\n",
    "        to_drop.append(fix_idx)\n",
    "        \n",
    "df.drop(index = to_drop, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "fix_idx_RM = [x for x in overlap_df[(overlap_df[1] == 'Non_Customer' ) & (overlap_df[3] < 1)][0].values if x in df.index]\n",
    "\n",
    "for fix_idx in fix_idx_RM:\n",
    "    df.loc[fix_idx, 'End_Time'] = df.loc[fix_idx,'Reservation_Time']+pd.to_timedelta(df.loc[fix_idx,'Reservation_Minutes'], 'm')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Battery Status"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2665"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add start time based on Reservation minutes\n",
    "df['Start_Time'] = [row.Reservation_Time+datetime.timedelta(minutes=row.Reservation_Minutes) for _, row in df.iterrows()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Vacancy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Haversine function\n",
    "def haversine(point1, point2):\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(np.radians, point1)\n",
    "    lat2, lon2 = map(np.radians, point2)\n",
    "\n",
    "    # Deltas\n",
    "    delta_lon = lon2 - lon1 \n",
    "    delta_lat = lat2 - lat1 \n",
    "    \n",
    "    # haversine formula \n",
    "    a = np.sin(delta_lat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in m\n",
    "    return c * r"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_sorted = df.sort_values(\"Reservation_Time\")\n",
    "df_sorted.CarID.nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = []\n",
    "for i, car in enumerate(df_sorted.CarID.unique()):\n",
    "    if car == '-':\n",
    "        continue\n",
    "    car_sub_df = df_sorted[df_sorted.CarID == car]\n",
    "    if not i%50:\n",
    "        print(f'{i} cars processed')\n",
    "    for (_, row1), (_, row2) in zip(car_sub_df[:-1].iterrows(),car_sub_df[1:].iterrows()):\n",
    "        park_time = row1['End_Time']\n",
    "        reservation_time = row2['Reservation_Time']\n",
    "        start_time = row2['Start_Time']\n",
    "        time_to_reservation = (row2['Reservation_Time']-row1['End_Time']).total_seconds()/3600\n",
    "        time_to_start = (row2['Start_Time']-row1['End_Time']).total_seconds()/3600\n",
    "        park_location_lat = row1['End_Lat']\n",
    "        park_location_long = row1['End_Long']\n",
    "        park_zone = row1['End_Zone']\n",
    "        park_fuel = row1['Fuel_End']\n",
    "        leave_fuel = row2['Fuel_Start']\n",
    "        engine = row1['Engine']\n",
    "        moved = haversine(row1.loc[['End_Lat','End_Long']].values, row2.loc[['Start_Lat','Start_Long']].values) \n",
    "        data.append([car, park_time,reservation_time, start_time, time_to_reservation, time_to_start, park_location_lat, park_location_long, park_zone, park_fuel, leave_fuel, engine, moved])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create new df\n",
    "df_vacancy = pd.DataFrame(data = data, columns = ['car', 'park_time', 'reservation_time', 'start_time','time_to_reservation', 'time_to_start', 'park_location_lat', 'park_location_long', 'park_zone', 'park_fuel', 'leave_fuel', 'engine', 'moved'])\n",
    "\n",
    "# Infer types\n",
    "df_vacancy = df_vacancy.convert_dtypes()\n",
    "\n",
    "# Save\n",
    "df_vacancy.to_csv('data/processed/Vacancy_new.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_vacancy[df_vacancy.park_location_lat < 10]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('GNN_env': conda)"
  },
  "interpreter": {
   "hash": "de6ba8d017a6d971cdf6b22028d449fee88a2d46fed4e213ca09e144ede73845"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
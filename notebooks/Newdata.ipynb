{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import glob\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import rtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/raw/SNData/*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    dfs.append(pd.read_csv(f, header=0, sep=\";\"))\n",
    "\n",
    "Full_data = pd.concat(dfs,ignore_index=True) # Save this to interim\n",
    "Full_data.to_csv('data/interim/Full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Group</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>CarID</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Rental_flag</th>\n",
       "      <th>RentalID</th>\n",
       "      <th>Rental_Usage_Type</th>\n",
       "      <th>Reservation_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Reservation_Minutes</th>\n",
       "      <th>Fuel_Start</th>\n",
       "      <th>Fuel_End</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Long</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>793639</td>\n",
       "      <td>WBY1Z21080V307924</td>\n",
       "      <td>I3</td>\n",
       "      <td>No</td>\n",
       "      <td>9335872135</td>\n",
       "      <td>Private</td>\n",
       "      <td>24.03.2016 11:48:43</td>\n",
       "      <td>02.04.2016 10:00:19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.678763</td>\n",
       "      <td>12.552853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>1035973</td>\n",
       "      <td>WBY1Z21080V307857</td>\n",
       "      <td>I3</td>\n",
       "      <td>No</td>\n",
       "      <td>9336114126</td>\n",
       "      <td>Private</td>\n",
       "      <td>30.03.2016 15:37:39</td>\n",
       "      <td>01.04.2016 00:40:38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>47</td>\n",
       "      <td>55.770626</td>\n",
       "      <td>12.519300</td>\n",
       "      <td>55.770389</td>\n",
       "      <td>12.518839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>998095</td>\n",
       "      <td>WBY1Z21020V307904</td>\n",
       "      <td>I3</td>\n",
       "      <td>No</td>\n",
       "      <td>9336153910</td>\n",
       "      <td>Private</td>\n",
       "      <td>31.03.2016 13:08:16</td>\n",
       "      <td>05.04.2016 08:32:25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>55.621588</td>\n",
       "      <td>12.606951</td>\n",
       "      <td>55.621532</td>\n",
       "      <td>12.606279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>999604</td>\n",
       "      <td>WBY1Z21010V307926</td>\n",
       "      <td>I3</td>\n",
       "      <td>No</td>\n",
       "      <td>9336158303</td>\n",
       "      <td>Private</td>\n",
       "      <td>31.03.2016 14:43:00</td>\n",
       "      <td>01.04.2016 07:10:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>55.770077</td>\n",
       "      <td>12.518914</td>\n",
       "      <td>55.769746</td>\n",
       "      <td>12.519123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>1035969</td>\n",
       "      <td>WBY1Z21070V308210</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "      <td>9336160465</td>\n",
       "      <td>Private</td>\n",
       "      <td>31.03.2016 15:21:36</td>\n",
       "      <td>01.04.2016 14:24:17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>55.770623</td>\n",
       "      <td>12.519791</td>\n",
       "      <td>55.770439</td>\n",
       "      <td>12.518937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633979</th>\n",
       "      <td>Customer</td>\n",
       "      <td>1070662</td>\n",
       "      <td>WBY1Z21010V308185</td>\n",
       "      <td>I3</td>\n",
       "      <td>No</td>\n",
       "      <td>9345011102</td>\n",
       "      <td>Private</td>\n",
       "      <td>30.09.2016 23:39:05</td>\n",
       "      <td>30.09.2016 23:50:54</td>\n",
       "      <td>5.16</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>55.694700</td>\n",
       "      <td>12.553776</td>\n",
       "      <td>55.678740</td>\n",
       "      <td>12.587144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633980</th>\n",
       "      <td>Customer</td>\n",
       "      <td>1041705</td>\n",
       "      <td>WBY1Z21080V308250</td>\n",
       "      <td>I3</td>\n",
       "      <td>No</td>\n",
       "      <td>9345011139</td>\n",
       "      <td>Private</td>\n",
       "      <td>30.09.2016 23:42:18</td>\n",
       "      <td>30.09.2016 23:52:14</td>\n",
       "      <td>3.44</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>55.648401</td>\n",
       "      <td>12.542945</td>\n",
       "      <td>55.641310</td>\n",
       "      <td>12.615295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633981</th>\n",
       "      <td>Customer</td>\n",
       "      <td>2112471</td>\n",
       "      <td>WBY1Z21020V308261</td>\n",
       "      <td>I3</td>\n",
       "      <td>No</td>\n",
       "      <td>9345011311</td>\n",
       "      <td>Private</td>\n",
       "      <td>30.09.2016 23:33:39</td>\n",
       "      <td>30.09.2016 23:52:03</td>\n",
       "      <td>8.17</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>55.664744</td>\n",
       "      <td>12.580875</td>\n",
       "      <td>55.719856</td>\n",
       "      <td>12.540863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633982</th>\n",
       "      <td>Customer</td>\n",
       "      <td>440147</td>\n",
       "      <td>WBY1Z21060V307954</td>\n",
       "      <td>I3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9345011420</td>\n",
       "      <td>Private</td>\n",
       "      <td>30.09.2016 23:41:56</td>\n",
       "      <td>30.09.2016 23:57:30</td>\n",
       "      <td>6.88</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>55.710676</td>\n",
       "      <td>12.566043</td>\n",
       "      <td>55.667453</td>\n",
       "      <td>12.619987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633983</th>\n",
       "      <td>Customer</td>\n",
       "      <td>1040093</td>\n",
       "      <td>WBY1Z21040V307953</td>\n",
       "      <td>I3</td>\n",
       "      <td>No</td>\n",
       "      <td>9345011439</td>\n",
       "      <td>Private</td>\n",
       "      <td>30.09.2016 23:42:52</td>\n",
       "      <td>30.09.2016 23:57:45</td>\n",
       "      <td>6.45</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>55.650799</td>\n",
       "      <td>12.591200</td>\n",
       "      <td>55.665603</td>\n",
       "      <td>12.549791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2633932 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Customer_Group  CustomerID              CarID Engine Rental_flag  \\\n",
       "0         Non_Customer      793639  WBY1Z21080V307924     I3          No   \n",
       "1         Non_Customer     1035973  WBY1Z21080V307857     I3          No   \n",
       "2         Non_Customer      998095  WBY1Z21020V307904     I3          No   \n",
       "3         Non_Customer      999604  WBY1Z21010V307926     I3          No   \n",
       "4         Non_Customer     1035969  WBY1Z21070V308210                 No   \n",
       "...                ...         ...                ...    ...         ...   \n",
       "2633979       Customer     1070662  WBY1Z21010V308185     I3          No   \n",
       "2633980       Customer     1041705  WBY1Z21080V308250     I3          No   \n",
       "2633981       Customer     2112471  WBY1Z21020V308261     I3          No   \n",
       "2633982       Customer      440147  WBY1Z21060V307954     I3         Yes   \n",
       "2633983       Customer     1040093  WBY1Z21040V307953     I3          No   \n",
       "\n",
       "           RentalID Rental_Usage_Type     Reservation_Time  \\\n",
       "0        9335872135           Private  24.03.2016 11:48:43   \n",
       "1        9336114126           Private  30.03.2016 15:37:39   \n",
       "2        9336153910           Private  31.03.2016 13:08:16   \n",
       "3        9336158303           Private  31.03.2016 14:43:00   \n",
       "4        9336160465           Private  31.03.2016 15:21:36   \n",
       "...             ...               ...                  ...   \n",
       "2633979  9345011102           Private  30.09.2016 23:39:05   \n",
       "2633980  9345011139           Private  30.09.2016 23:42:18   \n",
       "2633981  9345011311           Private  30.09.2016 23:33:39   \n",
       "2633982  9345011420           Private  30.09.2016 23:41:56   \n",
       "2633983  9345011439           Private  30.09.2016 23:42:52   \n",
       "\n",
       "                    End_Time  Revenue  Distance  Reservation_Minutes  \\\n",
       "0        02.04.2016 10:00:19     0.00         0                    0   \n",
       "1        01.04.2016 00:40:38     0.00         0                    0   \n",
       "2        05.04.2016 08:32:25     0.00         2                    1   \n",
       "3        01.04.2016 07:10:00     0.00         0                    1   \n",
       "4        01.04.2016 14:24:17     0.00         0                    1   \n",
       "...                      ...      ...       ...                  ...   \n",
       "2633979  30.09.2016 23:50:54     5.16         4                   10   \n",
       "2633980  30.09.2016 23:52:14     3.44         6                    8   \n",
       "2633981  30.09.2016 23:52:03     8.17         9                    3   \n",
       "2633982  30.09.2016 23:57:30     6.88         9                    4   \n",
       "2633983  30.09.2016 23:57:45     6.45         6                    1   \n",
       "\n",
       "         Fuel_Start  Fuel_End  Start_Lat  Start_Long    End_Lat   End_Long  \n",
       "0                 0         0  55.678763   12.552853   0.000000   0.000000  \n",
       "1                62        47  55.770626   12.519300  55.770389  12.518839  \n",
       "2                85        79  55.621588   12.606951  55.621532  12.606279  \n",
       "3                 0        71  55.770077   12.518914  55.769746  12.519123  \n",
       "4                53        52  55.770623   12.519791  55.770439  12.518937  \n",
       "...             ...       ...        ...         ...        ...        ...  \n",
       "2633979          46        41  55.694700   12.553776  55.678740  12.587144  \n",
       "2633980          59        52  55.648401   12.542945  55.641310  12.615295  \n",
       "2633981          39        30  55.664744   12.580875  55.719856  12.540863  \n",
       "2633982          44        35  55.710676   12.566043  55.667453  12.619987  \n",
       "2633983          92        86  55.650799   12.591200  55.665603  12.549791  \n",
       "\n",
       "[2633932 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 53 rows with na values\n",
    "df = Full_data.dropna()\n",
    "\n",
    "# Rename Columns to English\n",
    "df. columns = ['Customer_Group', 'CustomerID', 'CarID', 'Engine', 'Rental_flag', 'RentalID', 'Rental_Usage_Type', 'Reservation_Time', 'End_Time', 'Revenue', 'Distance', 'Drives', 'Reservation_Minutes','Fuel_Start','Fuel_End','Start_Lat', 'Start_Long', 'End_Lat', 'End_Long']\n",
    "\n",
    "# Fix type\n",
    "df = df.astype({'CustomerID': 'int32', 'RentalID': 'int64'})\n",
    "\n",
    "# Drop drives as it has no info (only ones)\n",
    "df.drop(columns = 'Drives', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all rows with a CarID as it can not be used\n",
    "df = df[df.CarID != '0']\n",
    "\n",
    "# Remoce DK from CarID so the same car does not have two id's\n",
    "df['CarID'] = df['CarID'].str.replace('DK','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engine has two types of missing values that is alligned\n",
    "df[\"Engine\"].replace({\" \": '0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a CarID already has an engine type assign that to the missing ones\n",
    "Engine_dict = {c: df[df.CarID == c].Engine.nunique() for c in df[df.Engine == '0'].CarID.unique()}\n",
    "for car, engine in Engine_dict.items():\n",
    "    if engine == 1:\n",
    "        continue\n",
    "    True_Engine = [x for x in df[df.CarID == car].Engine.unique() if x!= '0'][0]\n",
    "    df.loc[(df.CarID == car) & (df.Engine == '0'), 'Engine'] = True_Engine\n",
    "\n",
    "# Populate the rest manual based on ID\n",
    "df.loc[(df.CarID == 'WBA1R5104J7B14310') & (df.Engine == '0'), 'Engine'] = '118I'\n",
    "df.loc[(df.CarID == 'WBA1R5104J5K58061') & (df.Engine == '0'), 'Engine'] = '118I'\n",
    "df.loc[(df.CarID == 'WBA1R5103K7D66678') & (df.Engine == '0'), 'Engine'] = '118I'\n",
    "df.loc[(df.CarID == 'WBY8P2105K7D70350') & (df.Engine == '0'), 'Engine'] = 'I3 120'\n",
    "df.loc[(df.CarID == 'WBY8P2102K7D70287') & (df.Engine == '0'), 'Engine'] = 'I3 120'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reservation_Time'] = pd.to_datetime(df['Reservation_Time'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], format=\"%d.%m.%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix trips where same user use same car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [07:39<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split data on Car level\n",
    "CarID_dict = dict(iter(df.groupby('CarID')))\n",
    "\n",
    "def fix_merges(dataframe, max_time_diff = 60):\n",
    "    dataframe = dataframe.sort_values(by = 'Reservation_Time')\n",
    "    # Get index where same customer uses the same car back to back\n",
    "    diff0_iloc = [dataframe.index.get_loc(x) for x in dataframe.index[(dataframe.CustomerID.diff() == 0).tolist()]]\n",
    "\n",
    "    # Find paris to be merged\n",
    "    merge_pairs = [(idx-1,idx) for idx in diff0_iloc if dataframe.iloc[idx-1].End_Time+pd.to_timedelta(max_time_diff+dataframe.iloc[idx].Reservation_Minutes,'m') > dataframe.iloc[idx].Reservation_Time]\n",
    "\n",
    "    # Model as graph to get cc\n",
    "    graph_model = nx.Graph(merge_pairs)\n",
    "    groups = [(min(cc),max(cc)) for cc in list(nx.connected_components(graph_model))]\n",
    "\n",
    "    # Populate \n",
    "    for pair in groups:\n",
    "        dataframe.loc[dataframe.index[pair[0]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']] = dataframe.loc[dataframe.index[pair[1]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']]\n",
    "\n",
    "\n",
    "    # Delete now unwanted rows\n",
    "    rows_to_delete = [x[1] for x in merge_pairs]\n",
    "    dataframe.drop(index = [dataframe.index[x] for x in rows_to_delete], inplace = True)\n",
    "\n",
    "    # Return fixed dataframe\n",
    "    return dataframe\n",
    "\n",
    "# Merge new datasets\n",
    "dfs = []\n",
    "for sub_df in tqdm.tqdm(CarID_dict.values()):\n",
    "    dfs.append(fix_merges(sub_df))\n",
    "\n",
    "df = pd.concat(dfs,ignore_index=False).sort_values(by = 'RentalID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix wierd times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winter Time\n",
    "WinterTimeIndex = df[(df.Reservation_Time > df.End_Time) & (df.End_Time.apply(lambda x: x.month) == 10) & (df.End_Time.apply(lambda x: x.hour) < 4)].index\n",
    "WinterTimeIndexBack = [2179859, 1683947, 1683948]\n",
    "WinterTimeIndexForward = [x for x in WinterTimeIndex if x not in WinterTimeIndexBack]\n",
    "df.loc[WinterTimeIndexBack, 'Reservation_Time'] = df.loc[WinterTimeIndexBack, 'Reservation_Time'] - pd.to_timedelta(1,'h')\n",
    "df.loc[WinterTimeIndexForward, 'End_Time'] = df.loc[WinterTimeIndexForward, 'End_Time'] + pd.to_timedelta(1,'h')\n",
    "\n",
    "# Remove remaining 50 observations as they will not introduce more vacancy time\n",
    "df.drop(index = df[df.Reservation_Time > df.End_Time].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Non-Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [00:43<00:00, 22.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split data on Car level\n",
    "CarID_dict = dict(iter(df.groupby('CarID')))\n",
    "\n",
    "def merge_NC(dataframe):\n",
    "    dataframe = dataframe.sort_values(by = 'Reservation_Time')\n",
    "    # Get index where non_customer\n",
    "    is_NC = dataframe.Customer_Group == 'Non_Customer'\n",
    "\n",
    "    # Find paris to be merged\n",
    "    merge_pairs = [(is_NC.index.get_loc(k1),is_NC.index.get_loc(k2)) for (k1, v1),(k2,v2) in zip(is_NC.iloc[:-1].iteritems(),is_NC.iloc[1:].iteritems()) if v1&v2]\n",
    "\n",
    "    # Model as graph to get cc\n",
    "    graph_model = nx.Graph(merge_pairs)\n",
    "    groups = [(min(cc),max(cc)) for cc in list(nx.connected_components(graph_model))]\n",
    "\n",
    "    # Populate \n",
    "    for pair in groups:\n",
    "        dataframe.loc[dataframe.index[pair[0]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']] = dataframe.loc[dataframe.index[pair[1]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']]\n",
    "\n",
    "    # Delete now unwanted rows\n",
    "    rows_to_delete = [x[1] for x in merge_pairs]\n",
    "    dataframe.drop(index = [dataframe.index[x] for x in rows_to_delete], inplace = True)\n",
    "\n",
    "    # Return fixed dataframe\n",
    "    return dataframe\n",
    "\n",
    "# Merge new datasets\n",
    "dfs = []\n",
    "for sub_df in tqdm.tqdm(CarID_dict.values()):\n",
    "    dfs.append(merge_NC(sub_df))\n",
    "\n",
    "df = pd.concat(dfs,ignore_index=False).sort_values(by = 'Reservation_Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CarID_dict = dict(iter(df.groupby('CarID')))\n",
    "tat = []\n",
    "endtat0 = []\n",
    "endtat1 = []\n",
    "endtat2 = []\n",
    "endtat3 = []\n",
    "\n",
    "for car,dataf in CarID_dict.items():\n",
    "    dataf = dataf.sort_values(by = 'Reservation_Time')\n",
    "    tap = list( zip( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]].Customer_Group.values, dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]+1].Customer_Group.values ) )\n",
    "    tat.extend( tap )\n",
    "\n",
    "    endtat0.extend( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]].index )\n",
    "    endtat1.extend( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]].Customer_Group )\n",
    "    endtat2.extend( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]+1].Customer_Group )\n",
    "    endtat3.extend( dataf.iloc[np.where(dataf.Reservation_Time.iloc[1:].values<dataf.End_Time.iloc[:-1].values)[0]].End_Lat )\n",
    "\n",
    "overlap_df = pd.DataFrame(data=[endtat0,endtat1,endtat2,endtat3]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1055312</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1167781</td>\n",
       "      <td>Customer</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>55.781131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656178</td>\n",
       "      <td>Customer</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>55.634312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1052599</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1444470</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1813952</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1822676</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1304046</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1359243</td>\n",
       "      <td>Customer</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>55.685669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1416307</td>\n",
       "      <td>Non_Customer</td>\n",
       "      <td>Customer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1             2          3\n",
       "0    1055312  Non_Customer      Customer        0.0\n",
       "1    1167781      Customer  Non_Customer  55.781131\n",
       "2    1656178      Customer  Non_Customer  55.634312\n",
       "3    1052599  Non_Customer      Customer        0.0\n",
       "4    1444470  Non_Customer      Customer        0.0\n",
       "..       ...           ...           ...        ...\n",
       "215  1813952  Non_Customer      Customer        0.0\n",
       "216  1822676  Non_Customer      Customer        0.0\n",
       "217  1304046  Non_Customer      Customer        0.0\n",
       "218  1359243      Customer  Non_Customer  55.685669\n",
       "219  1416307  Non_Customer      Customer        0.0\n",
       "\n",
       "[220 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix those with bad end_loc\n",
    "fix_idx0 = overlap_df[(overlap_df[1] == 'Customer') & (overlap_df[3] < 1)][0].values\n",
    "df.loc[fix_idx0, 'End_Time'] = df.loc[fix_idx0, 'Reservation_Time'].values + pd.to_timedelta(1,'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine function\n",
    "def haversine(point1, point2):\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(np.radians, point1)\n",
    "    lat2, lon2 = map(np.radians, point2)\n",
    "\n",
    "    # Deltas\n",
    "    delta_lon = lon2 - lon1 \n",
    "    delta_lat = lat2 - lat1 \n",
    "    \n",
    "    # haversine formula \n",
    "    a = np.sin(delta_lat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in m\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the other C-C to average of the two reservation times\n",
    "fix_idxP = overlap_df[(overlap_df[1] == 'Customer') & (overlap_df[3] > 1)][0].values\n",
    "    \n",
    "for fix_idx in fix_idxP:\n",
    "    # Get sub_df\n",
    "    tmp_car_df = df[df.CarID == df.loc[fix_idx].CarID]\n",
    "    \n",
    "    # Get iloc in sub_df of to be fixed\n",
    "    fix_iloc = tmp_car_df.index.get_loc(fix_idx)\n",
    "\n",
    "    # Get end loc of curent and start of next\n",
    "    end_loc = tmp_car_df.loc[fix_idx, ['End_Lat', 'End_Long']].values\n",
    "    start_loc = tmp_car_df.loc[tmp_car_df.index[fix_iloc+1], ['Start_Lat', 'Start_Long']].values\n",
    "\n",
    "    # If parked at same place adjust\n",
    "    if haversine(end_loc, start_loc) < 100:\n",
    "        avg_time = df.loc[fix_idx,'Reservation_Time'] + (df.loc[tmp_car_df.index[fix_iloc+1],'Reservation_Time'] - df.loc[fix_idx,'Reservation_Time']) / 2\n",
    "        df.loc[fix_idx,'End_Time'] = avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual fixes/guestimates\n",
    "df.loc[51903,'End_Time'] = pd.Timestamp(\"2016-11-03 20:00:00\")\n",
    "df.loc[661452,'End_Time'] = pd.Timestamp(\"2017-12-01 17:00:00\")\n",
    "df.loc[52806,'End_Time'] = pd.Timestamp(\"2016-11-05 08:00:10\")\n",
    "df.loc[2376045,'Reservation_Time'] = pd.Timestamp(\"2016-08-05 12:49:38\")\n",
    "df.loc[661513,'End_Time'] = pd.Timestamp(\"2017-12-02 16:16:24\")\n",
    "df.loc[784104,'End_Time'] = pd.Timestamp(\"2017-10-04 12:20:10\")\n",
    "\n",
    "df.drop(index = [22088, 25828, 809192, 664080, 1137264, 713741, 1604116, 2470015, 404202, 661521, 404308], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2411071 entries, 1969578 to 1457863\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   Customer_Group       object        \n",
      " 1   CustomerID           int32         \n",
      " 2   CarID                object        \n",
      " 3   Engine               object        \n",
      " 4   Rental_flag          object        \n",
      " 5   RentalID             int64         \n",
      " 6   Rental_Usage_Type    object        \n",
      " 7   Reservation_Time     datetime64[ns]\n",
      " 8   End_Time             datetime64[ns]\n",
      " 9   Revenue              float64       \n",
      " 10  Distance             int64         \n",
      " 11  Reservation_Minutes  int64         \n",
      " 12  Fuel_Start           int64         \n",
      " 13  Fuel_End             int64         \n",
      " 14  Start_Lat            float64       \n",
      " 15  Start_Long           float64       \n",
      " 16  End_Lat              float64       \n",
      " 17  End_Long             float64       \n",
      "dtypes: datetime64[ns](2), float64(5), int32(1), int64(5), object(5)\n",
      "memory usage: 340.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Save interim\n",
    "df.to_csv('data/interim/s_version.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_idxCNC = overlap_df[(overlap_df[1]=='Customer') & (overlap_df[2]=='Non_Customer')][0].values\n",
    "for fix_idx in fix_idxCNC:\n",
    "    # Get sub_df\n",
    "    tmp_car_df = df[df.CarID == df.loc[fix_idx].CarID]\n",
    "    \n",
    "    # Get iloc in sub_df of to be fixed\n",
    "    fix_iloc = tmp_car_df.index.get_loc(fix_idx)\n",
    "\n",
    "    # Replace values\n",
    "    df.loc[fix_idx,['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']] = df.loc[tmp_car_df.index[fix_iloc+1],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']]\n",
    "\n",
    "    # Dtop the old NC row\n",
    "    df.drop(tmp_car_df.index[fix_iloc+1], inplace = True)\n",
    "\n",
    "#df.drop(index = 888104, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1055312, 1052599, 1444470, 995186, 2433923, 615309, 2540107,\n",
       "       2397136, 1642807, 1619773, 2281113, 1211776, 1072166, 1279786,\n",
       "       1279809, 982965, 440041, 2196102, 1250112, 1697536, 1716174,\n",
       "       1783544, 1791055, 1475190, 442945, 449190, 586202, 600000, 960571,\n",
       "       818752, 172717, 871418, 785515, 943031, 893511, 2272533, 2057969,\n",
       "       2067461, 1136197, 1564453, 1280699, 850099, 785555, 2407154,\n",
       "       854183, 986614, 2560234, 2160001, 987355, 1589134, 1578822,\n",
       "       2367379, 986247, 438413, 579926, 625661, 2274667, 791672, 765940,\n",
       "       248843, 2361115, 1138887, 654041, 2098815, 2132711, 975945,\n",
       "       1138900, 2212041, 410530, 2139234, 2002473, 804400, 1773133,\n",
       "       2367374, 1234799, 2012836, 1352766, 1061131, 2368344, 1565559,\n",
       "       496290, 413857, 941872, 983015, 802628, 2220918, 672193, 2032504,\n",
       "       966044, 632821, 763558, 2366647, 2128399, 868299, 1341035, 2407172,\n",
       "       1229655, 662657, 1997594, 1259575, 2527189, 2533837, 1016940,\n",
       "       1140421, 158918, 415236, 817935, 872049, 974673, 1239203, 886165,\n",
       "       901923, 2087352, 1982908, 2198448, 1214082, 925181, 2047910,\n",
       "       185321, 2502850, 2371278, 767721, 1037308, 679533, 1162136,\n",
       "       2217218, 2485588, 2076052, 972515, 1268340, 1581169, 2073467,\n",
       "       1557963, 1140164, 2499315, 698502, 2371303, 756897, 1970388,\n",
       "       1276674, 493188, 592635, 1918894, 1361565, 1808737, 580002,\n",
       "       1412360, 1635715, 1898417, 579943, 1023230, 1147536, 1098673,\n",
       "       1146789, 1813952, 1822676, 1304046, 1416307], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_idx_NC0 = overlap_df[(overlap_df[1] ==  'Non_Customer') & (overlap_df[3] < 1)][0].values\n",
    "fix_idx_NC0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_idx_NC0 = overlap_df[(overlap_df[1] ==  'Non_Customer') & (overlap_df[3] < 1)][0].values\n",
    "to_drop = []\n",
    "\n",
    "for fix_idx in fix_idx_NC0:\n",
    "    # Get sub_df\n",
    "    try:\n",
    "        tmp_car_df = df[df.CarID == df.loc[fix_idx].CarID].sort_values(by = 'Reservation_Time')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Get iloc in sub_df of to be fixed\n",
    "    fix_iloc = tmp_car_df.index.get_loc(fix_idx)\n",
    "\n",
    "    # Get the two start locs\n",
    "    start_loc0 = tmp_car_df.loc[tmp_car_df.index[fix_iloc-1], ['Start_Lat', 'Start_Long']].values\n",
    "    start_loc1 = tmp_car_df.loc[fix_idx, ['Start_Lat', 'Start_Long']].values\n",
    "    start_loc2 = tmp_car_df.loc[tmp_car_df.index[fix_iloc+1], ['Start_Lat', 'Start_Long']].values\n",
    "\n",
    "    # If left same spot then drop\n",
    "    if haversine(start_loc0, start_loc1) < 100:\n",
    "        to_drop.append(fix_idx)\n",
    "    if haversine(start_loc1, start_loc2) < 100:\n",
    "        to_drop.append(fix_idx)\n",
    "        \n",
    "df.drop(index = to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_idx_RM = [x for x in overlap_df[(overlap_df[1] == 'Non_Customer' ) & (overlap_df[3] < 1)][0].values if x in df.index]\n",
    "\n",
    "for fix_idx in fix_idx_RM:\n",
    "    df.loc[fix_idx, 'End_Time'] = df.loc[fix_idx,'Reservation_Time']+pd.to_timedelta(df.loc[fix_idx,'Reservation_Minutes'], 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Reservation_Time >= pd.Timestamp(\"2018-01-01\")].CarID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut out 2018 and 2019 and fix fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1819 = df[df.Reservation_Time >= pd.Timestamp(\"2018-01-01\")]\n",
    "df1819['TripDist'] = df1819.apply(lambda x: haversine([x['Start_Lat'], x['Start_Long']], [x['End_Lat'], x['End_Long']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manuel -1 fixes. Remaining -1 are start so no prob there\n",
    "df1819.loc[516417,'Fuel_End'], df1819.loc[516674,'Fuel_Start'] = 78,78\n",
    "df1819.loc[1423849,'Fuel_End'], df1819.loc[1424064,'Fuel_Start'] = 92,92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927/927 [02:01<00:00,  7.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fix single missing\n",
    "CarID_dict = CarID_dict = dict(iter(df1819.groupby('CarID')))\n",
    "for sub_df in tqdm.tqdm(CarID_dict.values()):\n",
    "    sub_df = sub_df.sort_values(by = 'Reservation_Time')\n",
    "    idx_fix_start = [sub_df.index.get_loc(x) for x in sub_df[sub_df.Fuel_Start == 0].index]\n",
    "\n",
    "    if len(idx_fix_start) == 0:\n",
    "        continue\n",
    "\n",
    "    # Ensure the ones are lone\n",
    "    idx_fix_start = [x for x in idx_fix_start if x-1 not in idx_fix_start and x+1 not in idx_fix_start]\n",
    "    #idx_fix_end =[x-1 for x in idx_fix_start]\n",
    "\n",
    "    for idx in idx_fix_start:\n",
    "        # Get average\n",
    "        replace_val = (sub_df.iloc[idx].Fuel_End+sub_df.iloc[idx-1].Fuel_Start)//2\n",
    "\n",
    "        # Replace\n",
    "        df1819.loc[sub_df.index[idx], 'Fuel_Start'] = replace_val\n",
    "        df1819.loc[sub_df.index[idx-1], 'Fuel_End'] = replace_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1819.drop(index = df1819[(df1819.Fuel_Start <= 0) & ((df1819.TripDist <= 0.1) | ((df1819.TripDist > 5000000)))].index, inplace = True)\n",
    "# Manual fixes\n",
    "df1819.drop(index = [221640, 223431, 224544, 227363], inplace = True)\n",
    "df1819.loc[2108824,'Fuel_Start'] = 48\n",
    "df1819.loc[208967,'Fuel_End'] = 74\n",
    "df1819.loc[241387,'Fuel_Start'] = 74\n",
    "df1819.loc[241387,'Fuel_End'] = 69\n",
    "df1819.loc[241859,'Fuel_Start'] = 69\n",
    "df1819.loc[241859,'Fuel_End'] = 62\n",
    "df1819.loc[1853849,'Fuel_Start'] = 100\n",
    "\n",
    "df1819.loc[1614655,'Fuel_Start'] = 100\n",
    "\n",
    "# Car WBY1Z21020V307871\n",
    "df1819.loc[2194695, 'Fuel_Start'] = 79\n",
    "df1819.loc[2195546, 'Fuel_Start'] = 73\n",
    "df1819.loc[2195720, 'Fuel_Start'] = 67\n",
    "df1819.loc[2195864, 'Fuel_Start'] = 54\n",
    "df1819.loc[2195905, 'Fuel_Start'] = 51\n",
    "df1819.loc[2195934, 'Fuel_Start'] = 48\n",
    "df1819.loc[2196040, 'Fuel_Start'] = 46\n",
    "df1819.loc[2196073, 'Fuel_Start'] = 44\n",
    "\n",
    "# Car WBY8P2105K7D70350\n",
    "df1819.loc[1810440, 'Fuel_Start'] = 100\n",
    "df1819.loc[1811631, 'Fuel_Start'] = 84\n",
    "df1819.loc[1812237, 'Fuel_Start'] = 73\n",
    "df1819.loc[1813020, 'Fuel_Start'] = 70\n",
    "df1819.loc[1814957, 'Fuel_Start'] = 68\n",
    "df1819.loc[1815464, 'Fuel_Start'] = 63\n",
    "df1819.loc[1818056, 'Fuel_Start'] = 61\n",
    "df1819.loc[1818503, 'Fuel_Start'] = 55\n",
    "df1819.loc[1818835, 'Fuel_Start'] = 54\n",
    "df1819.loc[1821416, 'Fuel_Start'] = 51\n",
    "df1819.loc[1822755, 'Fuel_Start'] = 50\n",
    "\n",
    "df1819.loc[1993339, 'Fuel_Start'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1702133\n",
      "1702120\n"
     ]
    }
   ],
   "source": [
    "print(len(df1819))\n",
    "# Merge NC again due to some being dropped\n",
    "# Split data on Car level\n",
    "CarID_dict = dict(iter(df1819.groupby('CarID')))\n",
    "\n",
    "def merge_NC(dataframe):\n",
    "    dataframe = dataframe.sort_values(by = 'Reservation_Time')\n",
    "    # Get index where non_customer\n",
    "    is_NC = dataframe.Customer_Group == 'Non_Customer'\n",
    "\n",
    "    # Find paris to be merged\n",
    "    merge_pairs = [(is_NC.index.get_loc(k1),is_NC.index.get_loc(k2)) for (k1, v1),(k2,v2) in zip(is_NC.iloc[:-1].iteritems(),is_NC.iloc[1:].iteritems()) if v1&v2]\n",
    "\n",
    "    # Model as graph to get cc\n",
    "    graph_model = nx.Graph(merge_pairs)\n",
    "    groups = [(min(cc),max(cc)) for cc in list(nx.connected_components(graph_model))]\n",
    "\n",
    "    # Populate \n",
    "    for pair in groups:\n",
    "        dataframe.loc[dataframe.index[pair[0]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']] = dataframe.loc[dataframe.index[pair[1]],['End_Time', 'Fuel_End', 'End_Lat', 'End_Long']]\n",
    "\n",
    "    # Delete now unwanted rows\n",
    "    rows_to_delete = [x[1] for x in merge_pairs]\n",
    "    dataframe.drop(index = [dataframe.index[x] for x in rows_to_delete], inplace = True)\n",
    "\n",
    "    # Return fixed dataframe\n",
    "    return dataframe\n",
    "\n",
    "# Merge new datasets\n",
    "dfs = []\n",
    "for sub_df in CarID_dict.values():\n",
    "    dfs.append(merge_NC(sub_df))\n",
    "\n",
    "df1819 = pd.concat(dfs,ignore_index=False).sort_values(by = 'Reservation_Time')\n",
    "print(len(df1819))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1819.to_csv('data/interim/t_version.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927/927 [00:17<00:00, 53.69it/s] \n"
     ]
    }
   ],
   "source": [
    "# Fix missing where start is available\n",
    "CarID_dict = CarID_dict = dict(iter(df1819.groupby('CarID')))\n",
    "for sub_df in tqdm.tqdm(CarID_dict.values()):\n",
    "    sub_df = sub_df.sort_values(by = 'Reservation_Time')\n",
    "    idx_fix_start = [sub_df.index.get_loc(x) for x in sub_df[sub_df.Fuel_Start <= 0].index if x > 0]\n",
    "\n",
    "    if len(idx_fix_start) == 0:\n",
    "        continue\n",
    "\n",
    "    idx_fix_start = [x for x in idx_fix_start if sub_df.loc[sub_df.index[x-1],'Fuel_End']>0]\n",
    "\n",
    "    for idx in idx_fix_start:\n",
    "        df1819.loc[sub_df.index[idx], 'Fuel_Start'] = df1819.loc[sub_df.index[idx-1], 'Fuel_End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for car in df1819[df1819.Fuel_Start <= 0].CarID.value_counts().keys():\n",
    "    sub_df = df1819[df1819.CarID == car]\n",
    "    idx_fix = [sub_df.index.get_loc(x) for x in sub_df[sub_df.Fuel_Start <= 0].index][0]\n",
    "    \n",
    "    if df1819.loc[sub_df.index[idx_fix],'Start_Lat'] == df1819.loc[sub_df.index[idx_fix-1],'Start_Lat']:\n",
    "        df1819.loc[sub_df.index[idx_fix],'Fuel_Start'] = df1819.loc[sub_df.index[idx_fix-1],'Fuel_Start']\n",
    "\n",
    "        df1819.drop(index = sub_df.index[idx_fix-1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAst manual fixes\n",
    "df1819.loc[2096334, 'Fuel_Start'] = 88\n",
    "df1819.loc[2013446, 'Fuel_Start'] = 100\n",
    "df1819.loc[2544201, 'Fuel_Start'] = 15\n",
    "df1819.loc[192176, 'Fuel_Start'] = 95\n",
    "df1819.loc[2111646, 'Fuel_Start'] = 22\n",
    "df1819.loc[2184762, 'Fuel_Start'] = 10\n",
    "df1819.loc[2474381, 'Fuel_Start'] = 5\n",
    "df1819.loc[2499013, 'Fuel_Start'] = 10\n",
    "df1819.loc[1798819, 'Fuel_Start'] = 6\n",
    "df1819.loc[518233, 'Fuel_Start'] = 97\n",
    "df1819.loc[585544, 'Fuel_Start'] = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix 0,0 locations\n",
    "\n",
    "We also accept the other ones outside Copenhagen as the cars must have been there. They can be removed in the vacancy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df1819[(df1819.Start_Lat < 5)].iterrows():\n",
    "    # Skip if first instance as it will unaffect vacancy\n",
    "    sub_df = df1819[df1819.CarID == row.CarID].sort_values('RentalID')\n",
    "    err_index = sub_df.index.get_loc(i)\n",
    "    if err_index == 0:\n",
    "        continue\n",
    "\n",
    "    # Populate based on previous end \n",
    "    df1819.loc[i, ['Start_Lat', 'Start_Long']] = sub_df.iloc[err_index-1].loc[['End_Lat','End_Long']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df1819[(df1819.End_Lat < 5)].iterrows():\n",
    "    sub_df = df1819[df1819.CarID == row.CarID].sort_values('RentalID')\n",
    "    err_index = sub_df.index.get_loc(i)\n",
    "\n",
    "    # Will fail if last index\n",
    "    try:\n",
    "        df1819.loc[i, ['End_Lat', 'End_Long']] = sub_df.iloc[err_index+1].loc[['Start_Lat','Start_Long']].values\n",
    "    except:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shapefile and set projection\n",
    "shapefile = gpd.read_file(\"../Zonekort/LTM_Zone3/zones_level3.shp\")\n",
    "shapefile = shapefile.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geoDF with geometry as starting point\n",
    "gdf_start = gpd.GeoDataFrame(df1819, geometry= gpd.points_from_xy(df1819.Start_Long, df1819.Start_Lat))\n",
    "\n",
    "# Set projection\n",
    "gdf_start = gdf_start.set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate zones based on which zone they are within\n",
    "gdpj_start  = gpd.sjoin(gdf_start, shapefile, op='within')\n",
    "df1819['Start_Zone'] = gdpj_start.zoneid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/pggbcw7949507j0lbw1gjngc0000gn/T/ipykernel_37866/2877733264.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  Start_zone_filler = {x: shapefile.zoneid[shapefile.distance(df1819.loc[x].geometry).sort_values().index[0]] for x in df1819.index[df1819['Start_Zone'].isna()]}\n"
     ]
    }
   ],
   "source": [
    "# Populate the rest based on which zone they are closest too\n",
    "Start_zone_filler = {x: shapefile.zoneid[shapefile.distance(df1819.loc[x].geometry).sort_values().index[0]] for x in df1819.index[df1819['Start_Zone'].isna()]}\n",
    "df1819['Start_Zone'] = df1819['Start_Zone'].fillna(Start_zone_filler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geoDF with geometry as end point\n",
    "gdf_end = gpd.GeoDataFrame(df1819, geometry= gpd.points_from_xy(df1819.End_Long, df1819.End_Lat))\n",
    "\n",
    "# Set projection\n",
    "gdf_end = gdf_end.set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate zones based on which zone they are within\n",
    "gdpj_end  = gpd.sjoin(gdf_end, shapefile, op='within')\n",
    "df1819['End_Zone'] = gdpj_end.zoneid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/pggbcw7949507j0lbw1gjngc0000gn/T/ipykernel_37866/4030688568.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'distance' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  End_zone_filler = {x: shapefile.zoneid[shapefile.distance(df1819.loc[x].geometry).sort_values().index[0]] for x in df1819.index[df1819['End_Zone'].isna()]}\n"
     ]
    }
   ],
   "source": [
    "# Populate the rest based on which zone they are closest too\n",
    "End_zone_filler = {x: shapefile.zoneid[shapefile.distance(df1819.loc[x].geometry).sort_values().index[0]] for x in df1819.index[df1819['End_Zone'].isna()]}\n",
    "df1819['End_Zone'] = df1819['End_Zone'].fillna(End_zone_filler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove geomery type and make IDs int columns\n",
    "df1819.drop(columns = 'geometry', inplace = True)\n",
    "df1819 = df1819.astype({'CustomerID': 'int32', 'RentalID': 'int64', 'Start_Zone': 'int32','End_Zone': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1702109 entries, 2062415 to 1457863\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   Customer_Group       object        \n",
      " 1   CustomerID           int32         \n",
      " 2   CarID                object        \n",
      " 3   Engine               object        \n",
      " 4   Rental_flag          object        \n",
      " 5   RentalID             int64         \n",
      " 6   Rental_Usage_Type    object        \n",
      " 7   Reservation_Time     datetime64[ns]\n",
      " 8   End_Time             datetime64[ns]\n",
      " 9   Revenue              float64       \n",
      " 10  Distance             int64         \n",
      " 11  Reservation_Minutes  int64         \n",
      " 12  Fuel_Start           int64         \n",
      " 13  Fuel_End             int64         \n",
      " 14  Start_Lat            float64       \n",
      " 15  Start_Long           float64       \n",
      " 16  End_Lat              float64       \n",
      " 17  End_Long             float64       \n",
      " 18  TripDist             float64       \n",
      " 19  Start_Zone           int32         \n",
      " 20  End_Zone             int32         \n",
      "dtypes: datetime64[ns](2), float64(6), int32(3), int64(5), object(5)\n",
      "memory usage: 330.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check types\n",
    "df1819.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweden and Bornholm\n",
    "#df[df.Start_Long > 13].sort_values(by = 'Reservation_Time')\n",
    "\n",
    "# Jutland\n",
    "#df[(df.Start_Long < 11) & (df.Start_Long > 0) & (df.Customer_Group == 'Customer')]\n",
    "\n",
    "# Car in Germany in the middle of the data..\n",
    "#df[df.CarID == 'WBY1Z21040V308181'].sort_values(by = 'Reservation_Time').iloc[-30:-20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start time based on Reservation minutes\n",
    "df['Start_Time'] = [row.Reservation_Time+datetime.timedelta(minutes=row.Reservation_Minutes) for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vacancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine function\n",
    "def haversine(point1, point2):\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(np.radians, point1)\n",
    "    lat2, lon2 = map(np.radians, point2)\n",
    "\n",
    "    # Deltas\n",
    "    delta_lon = lon2 - lon1 \n",
    "    delta_lat = lat2 - lat1 \n",
    "    \n",
    "    # haversine formula \n",
    "    a = np.sin(delta_lat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in m\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = df1819.sort_values(\"Reservation_Time\")\n",
    "df_sorted.CarID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv('data/processed/Full_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 927/927 [21:40<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "CarID_dict = CarID_dict = dict(iter(df1819.groupby('CarID')))\n",
    "\n",
    "data = []\n",
    "for car, sub_df in tqdm.tqdm(CarID_dict.items()):\n",
    "    for (_, row1), (_, row2) in zip(sub_df[:-1].iterrows(),sub_df[1:].iterrows()):\n",
    "        park_time = row1['End_Time']\n",
    "        reservation_time = row2['Reservation_Time']\n",
    "        #start_time = row2['Start_Time']\n",
    "        time_to_reservation = (row2['Reservation_Time']-row1['End_Time']).total_seconds()/3600\n",
    "        #time_to_start = (row2['Start_Time']-row1['End_Time']).total_seconds()/3600\n",
    "        park_location_lat = row1['End_Lat']\n",
    "        park_location_long = row1['End_Long']\n",
    "        leave_location_lat = row2['Start_Lat']\n",
    "        leave_location_long = row2['Start_Long']\n",
    "        park_zone = row1['End_Zone']\n",
    "        leave_zone = row2['Start_Zone']\n",
    "        park_fuel = row1['Fuel_End']\n",
    "        leave_fuel = row2['Fuel_Start']\n",
    "        engine = row1['Engine']\n",
    "        moved = haversine(row1.loc[['End_Lat','End_Long']].values, row2.loc[['Start_Lat','Start_Long']].values) \n",
    "        prev_customer = row1['Customer_Group']\n",
    "        next_customer = row2['Customer_Group']\n",
    "        data.append([car, park_time,reservation_time, time_to_reservation, park_location_lat, park_location_long, leave_location_lat, leave_location_long, park_zone, leave_zone, park_fuel, leave_fuel, engine, moved, prev_customer, next_customer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df\n",
    "df_vacancy = pd.DataFrame(data = data, columns = ['car', 'park_time', 'reservation_time', 'time_to_reservation', 'park_location_lat', 'park_location_long', 'leave_location_lat', 'leave_location_long', 'park_zone', 'leave_zone', 'park_fuel', 'leave_fuel', 'engine', 'moved', 'prev_customer', 'next_customer'])\n",
    "\n",
    "# Infer types\n",
    "df_vacancy = df_vacancy.convert_dtypes()\n",
    "\n",
    "# Save\n",
    "df_vacancy.to_csv('data/processed/Vacancy_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vacancy[df_vacancy.park_location_lat < 10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5509f31e2044e4d39f528bdd5e1bbe95ee9581822c64151f31115901a677525b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('GNN_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

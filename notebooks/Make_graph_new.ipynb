{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import folium\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric import utils, data\n",
    "\n",
    "def haversine_start(df, car1, car2, max_dist = 1500):\n",
    "    def _edge_weight(x, max_dist):\n",
    "        return max((max_dist-x)/max_dist,0)\n",
    "    dfc1 = df[df.car == car1]\n",
    "    dfc2 = df[df.car == car2]\n",
    "\n",
    "    point1 = dfc1[['leave_location_lat','leave_location_long']].values[0]\n",
    "    point2 = dfc2[['leave_location_lat','leave_location_long']].values[0]\n",
    "    #return point1\n",
    "\n",
    "    # convert decimal degrees to radians\n",
    "    lat1, lon1 = map(np.radians, point1)\n",
    "    lat2, lon2 = map(np.radians, point2)\n",
    "\n",
    "    # Deltas\n",
    "    delta_lon = lon2 - lon1 \n",
    "    delta_lat = lat2 - lat1 \n",
    "    \n",
    "    # haversine formula \n",
    "    a = np.sin(delta_lat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371000 # Radius of earth in m\n",
    "    return _edge_weight(c * r, max_dist)\n",
    "\n",
    "def haversine_add(current_locs, to_add, max_dist = 1500):\n",
    "    def _edge_weight(x, max_dist):\n",
    "        return max((max_dist-x)/max_dist,0)\n",
    "    def _haversine(point1, lat2, lon2):\n",
    "        \n",
    "         # convert decimal degrees to radians\n",
    "        lat1, lon1 = map(np.radians, point1)\n",
    "\n",
    "        # Deltas\n",
    "        delta_lon = lon2 - lon1 \n",
    "        delta_lat = lat2 - lat1 \n",
    "        \n",
    "        # haversine formula \n",
    "        a = np.sin(delta_lat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon/2)**2\n",
    "        c = 2 * np.arcsin(np.sqrt(a)) \n",
    "        r = 6371000 # Radius of earth in m\n",
    "        return c * r\n",
    "\n",
    "    leave_lat_add, leave_long_add = to_add.leave_location_lat, to_add.leave_location_long\n",
    "\n",
    "    lat2, lon2 = map(np.radians, [leave_lat_add,leave_long_add])\n",
    "\n",
    "    new_weights = [_edge_weight(_haversine(loc, lat2, lon2), max_dist) for loc in current_locs]\n",
    "\n",
    "    return new_weights\n",
    "\n",
    "\n",
    "def delete_rc(mat, i):\n",
    "    # row\n",
    "    n = mat.indptr[i+1] - mat.indptr[i]\n",
    "    if n > 0:\n",
    "        mat.data[mat.indptr[i]:-n] = mat.data[mat.indptr[i+1]:]\n",
    "        mat.data = mat.data[:-n]\n",
    "        mat.indices[mat.indptr[i]:-n] = mat.indices[mat.indptr[i+1]:]\n",
    "        mat.indices = mat.indices[:-n]\n",
    "    mat.indptr[i:-1] = mat.indptr[i+1:]\n",
    "    mat.indptr[i:] -= n\n",
    "    mat.indptr = mat.indptr[:-1]\n",
    "    mat._shape = (mat._shape[0]-1, mat._shape[1])\n",
    "\n",
    "    # col\n",
    "    mat = mat.tocsc()\n",
    "    n = mat.indptr[i+1] - mat.indptr[i]\n",
    "    if n > 0:\n",
    "        mat.data[mat.indptr[i]:-n] = mat.data[mat.indptr[i+1]:]\n",
    "        mat.data = mat.data[:-n]\n",
    "        mat.indices[mat.indptr[i]:-n] = mat.indices[mat.indptr[i+1]:]\n",
    "        mat.indices = mat.indices[:-n]\n",
    "    mat.indptr[i:-1] = mat.indptr[i+1:]\n",
    "    mat.indptr[i:] -= n\n",
    "    mat.indptr = mat.indptr[:-1]\n",
    "    mat._shape = (mat._shape[0], mat._shape[1]-1)\n",
    "\n",
    "    return mat.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3401726 entries, 0 to 3401725\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   car                  object        \n",
      " 1   time                 datetime64[ns]\n",
      " 2   time_to_reservation  float32       \n",
      " 3   park_location_lat    float32       \n",
      " 4   park_location_long   float32       \n",
      " 5   leave_location_lat   float32       \n",
      " 6   leave_location_long  float32       \n",
      " 7   park_zone            int32         \n",
      " 8   leave_zone           int32         \n",
      " 9   park_fuel            int8          \n",
      " 10  leave_fuel           int8          \n",
      " 11  engine               object        \n",
      " 12  moved                float32       \n",
      " 13  prev_customer        bool          \n",
      " 14  next_customer        bool          \n",
      " 15  movedTF              bool          \n",
      " 16  action               bool          \n",
      "dtypes: bool(4), datetime64[ns](1), float32(6), int32(2), int8(2), object(2)\n",
      "memory usage: 227.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed/VacancySplit.csv', index_col=0, parse_dates = [2]).astype({'time_to_reservation': 'float32', 'park_location_lat': 'float32', 'park_location_long': 'float32', 'leave_location_lat': 'float32', 'leave_location_long': 'float32', 'park_zone': 'int32', 'leave_zone': 'int32', 'park_fuel': 'int8', 'leave_fuel': 'int8', 'moved': 'float32', 'movedTF': 'bool'})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start_Time = pd.Timestamp('2018-07-09 14:27:00')\n",
    "start_df = df[df.time <= Start_Time]\n",
    "propegate_df = df[df.time > Start_Time]\n",
    "\n",
    "# Start\n",
    "CarID_dict_start = dict(iter(start_df.groupby('car')))\n",
    "Start_Garph_data = []\n",
    "\n",
    "for sub_df in CarID_dict_start.values():\n",
    "    last_obs = sub_df.iloc[-1]\n",
    "    if last_obs.action: # True is park\n",
    "        Start_Garph_data.append(last_obs)\n",
    "\n",
    "start_df_graph = pd.DataFrame(Start_Garph_data).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 431/431 [04:33<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "max_dist = 1500\n",
    "def _edge_weight(x, max_dist):\n",
    "        return max((max_dist-x)/max_dist,0)\n",
    "A = pd.DataFrame(data = [[haversine_start(start_df_graph, car1, car2) for car1 in start_df_graph.car] for car2 in tqdm(start_df_graph.car)], index = start_df_graph.car, columns=start_df_graph.car, dtype='float16')\n",
    "\n",
    "# And make it sparse\n",
    "As = sparse.csr_matrix(A.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "As = sparse.csr_matrix(A.values)\n",
    "Graph_dict = {pd.Timestamp('2018-07-09 14:27:00'): (start_df_graph ,As)}\n",
    "node_data = start_df_graph.set_index('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6999/2800087 [02:05<13:55:48, 55.70it/s]\n"
     ]
    }
   ],
   "source": [
    "positive_time = propegate_df[propegate_df.action].time.diff().shift(-1) > pd.Timedelta(0,'s')\n",
    "positive_time[-1] = True\n",
    "\n",
    "new_day = (propegate_df.time.dt.date.diff().shift(-1) > pd.Timedelta(0,'s'))\n",
    "new_day[-1] = True\n",
    "\n",
    "i = 0\n",
    "for idx, next_row in tqdm(propegate_df.iterrows(), total = propegate_df.shape[0]):\n",
    "    if next_row.action: # True is park\n",
    "        # Get current locs\n",
    "        locs = [[attr['leave_location_lat'], attr['leave_location_long']] for _, attr in node_data.iterrows()]\n",
    "        \n",
    "        # Add to node data\n",
    "        node_data = node_data.append(next_row.rename(index = next_row['car']).iloc[1:16], verify_integrity = True)\n",
    "\n",
    "        # Calculate new weights\n",
    "        new_weights = haversine_add(locs, next_row, max_dist = 1500)\n",
    "\n",
    "        # Add new weights to adjacency\n",
    "        As = sparse.hstack([sparse.vstack([As,sparse.csr_matrix(new_weights)]).tocsc(), sparse.csc_matrix(new_weights+[1]).T]).tocsr()\n",
    "\n",
    "    else:\n",
    "        # Getindex\n",
    "        idx_to_drop = np.where(node_data.index == next_row.car)[0][0]\n",
    "\n",
    "        # Drop it\n",
    "        As = delete_rc(As, idx_to_drop)\n",
    "\n",
    "        # Drop from feature-matrix\n",
    "        node_data.drop(index = next_row.car, inplace=True)\n",
    "        \n",
    "    # Save graph if new time \n",
    "    if positive_time.get(idx):\n",
    "        Graph_dict[next_row.time] = (node_data.copy(), As.copy())\n",
    "\n",
    "    # Save file every day on last obs\n",
    "    if new_day[idx]:\n",
    "        f_name = next_row.time.strftime('%Y%m%d')+'.pickle'\n",
    "        with open(f_name, 'wb') as handle:\n",
    "            pickle.dump(Graph_dict, handle, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # Clear memory\n",
    "        Graph_dict = {}\n",
    "\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    if i == 7000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To PTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_zones = propegate_df.park_zone.unique()\n",
    "leave_zones = propegate_df.leave_zone.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/processed/zones.npy', 'wb') as f:\n",
    "    np.save(f, propegate_df.park_zone.unique())\n",
    "    np.save(f, propegate_df.leave_zone.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20180710.pickle', 'rb') as f:\n",
    "    tenth = pickle.load(f)\n",
    "\n",
    "tmp1 = tenth[pd.Timestamp('2018-07-10 00:01:27')]\n",
    "tmp2 = tenth[pd.Timestamp('2018-07-10 00:02:04')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_PTG(graph, park_zones, leave_zones):\n",
    "    attr, adj = graph\n",
    "\n",
    "    # Slice\n",
    "    _, labels = connected_components(csgraph=adj, directed=False, return_labels=True)\n",
    "    newl = labels[-1]\n",
    "    indices = labels == newl   \n",
    "\n",
    "    attr = attr[indices]\n",
    "    adj = adj[indices,:].tocsc()[:,indices].tocsr()\n",
    "\n",
    "    # Binarize\n",
    "    attr[[\"prev_customer\", \"next_customer\"]] = attr[[\"prev_customer\", \"next_customer\"]].astype(int)\n",
    "\n",
    "    # One hot encoding\n",
    "    attr['park_zone'] = pd.Categorical(attr['park_zone'], categories=park_zones)\n",
    "    attr = pd.get_dummies(attr, columns= ['park_zone'], prefix='pz')\n",
    "\n",
    "    attr['leave_zone'] = pd.Categorical(attr['leave_zone'], categories=leave_zones)\n",
    "    attr = pd.get_dummies(attr, columns = ['leave_zone'], prefix='lz')\n",
    "\n",
    "    attr['engine']= pd.Categorical(attr['engine'], categories=['118I', 'I3', 'COOPER', 'X1'])\n",
    "    attr = pd.get_dummies(attr, columns = ['engine'], prefix='eng')\n",
    "\n",
    "    # Get edges\n",
    "    edge_index, edge_weight = utils.convert.from_scipy_sparse_matrix(adj)\n",
    "\n",
    "    # Make pytorch data type\n",
    "    d = data.Data(x = torch.tensor(attr.filter(regex = 'park_fuel|pz|lz|eng').values), edge_index=edge_index, edge_attr=edge_weight, y = torch.tensor(attr.time_to_reservation.values))\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1900/1900 [00:34<00:00, 55.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "loader = DataLoader([make_PTG(g,park_zones,leave_zones) for g in tqdm(tenth.values())], batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,   441,   883,  1324,  1764,  2205,  2646,  3088,  3530,  3972,\n",
       "         4415,  4859,  5302,  5745,  6189,  6633,  7073,  7514,  7954,  8394,\n",
       "         8834,  9274,  9715, 10155, 10594, 11034, 11474, 11915, 12357, 12800,\n",
       "        13244, 13688, 14130])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader)).ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (batch0): BatchNorm(366)\n",
      "  (conv1): GCNConv(366, 512)\n",
      "  (batch1): BatchNorm(512)\n",
      "  (conv2): GCNConv(512, 512)\n",
      "  (batch2): BatchNorm(512)\n",
      "  (conv3): GCNConv(512, 512)\n",
      "  (batch3): BatchNorm(512)\n",
      "  (conv4): GCNConv(512, 1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, TransformerConv, BatchNorm, SAGEConv, GNNExplainer\n",
    "import torch.nn.functional as F\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, ):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.batch0 = BatchNorm(num_features)\n",
    "\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.batch1 = BatchNorm(hidden_channels)\n",
    "\n",
    "        self.conv2 = GCNConv(hidden_channels, int(hidden_channels))\n",
    "        self.batch2 = BatchNorm(int(hidden_channels))\n",
    "\n",
    "        self.conv3 = GCNConv(int(hidden_channels), int(hidden_channels))\n",
    "        self.batch3 = BatchNorm(int(hidden_channels))\n",
    "        \n",
    "        self.conv4 = GCNConv(int(hidden_channels), 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.batch1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.batch2(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.batch3(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "  \n",
    "        x = self.conv4(x, edge_index)\n",
    "        #x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = GCN(num_features=366, hidden_channels=512).to(device)\n",
    "#d.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717533"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=5e-4, nesterov=True, momentum=0.9)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "def train():\n",
    "  model.train()\n",
    "  optimizer.zero_grad()  # Clear gradients.\n",
    "  out = model(data.x.to(torch.float), data.edge_index)  # Perform a single forward pass.\n",
    "  loss = criterion(out[data.train_mask], data.y[data.train_mask].to(torch.float))  # Compute the loss solely based on the training nodes.\n",
    "  loss.backward()  # Derive gradients.\n",
    "  optimizer.step()  # Update parameters based on gradients.\n",
    "  return loss\n",
    "\n",
    "def valid():\n",
    "  model.eval()\n",
    "  out = model(data.x.to(torch.float), data.edge_index) \n",
    "  loss = criterion(out[data.val_mask], data.y[data.val_mask].to(torch.float))\n",
    "  return loss\n",
    "\n",
    "for epoch in range(0, 2501):\n",
    "  train_loss = train().detach().cpu()\n",
    "  valid_loss = valid().detach().cpu()\n",
    "  train_loss_list.append(train_loss)\n",
    "  valid_loss_list.append(valid_loss)\n",
    "  if epoch % 100 == 0:\n",
    "      print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.datasets.tu_dataset.TUDataset"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GNN_env/lib/python3.9/site-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "propegate_df[\"engine\"].replace({'I3 94': 'I3', 'I3 120': 'I3', 'X1 SDRIVE18I': 'X1', 'X2 SDRIVE18I': 'X1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.get_dummies(propegate_df, columns = ['park_zone', 'leave_zone', 'engine'], prefix = ['pz', 'lz', 'eng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>time</th>\n",
       "      <th>time_to_reservation</th>\n",
       "      <th>park_location_lat</th>\n",
       "      <th>park_location_long</th>\n",
       "      <th>leave_location_lat</th>\n",
       "      <th>leave_location_long</th>\n",
       "      <th>park_fuel</th>\n",
       "      <th>leave_fuel</th>\n",
       "      <th>moved</th>\n",
       "      <th>...</th>\n",
       "      <th>lz_370133</th>\n",
       "      <th>lz_376124</th>\n",
       "      <th>lz_461123</th>\n",
       "      <th>lz_561133</th>\n",
       "      <th>lz_730313</th>\n",
       "      <th>lz_751116</th>\n",
       "      <th>eng_118I</th>\n",
       "      <th>eng_COOPER</th>\n",
       "      <th>eng_I3</th>\n",
       "      <th>eng_X1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>601639</th>\n",
       "      <td>WBA1R5105J7B14249</td>\n",
       "      <td>2018-07-09 14:27:31</td>\n",
       "      <td>6.179444</td>\n",
       "      <td>55.770130</td>\n",
       "      <td>12.518211</td>\n",
       "      <td>55.770130</td>\n",
       "      <td>12.518211</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601640</th>\n",
       "      <td>WBY1Z21040V307970</td>\n",
       "      <td>2018-07-09 14:27:37</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>55.674522</td>\n",
       "      <td>12.559719</td>\n",
       "      <td>55.674522</td>\n",
       "      <td>12.559719</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601641</th>\n",
       "      <td>WMWXR3102KTK68969</td>\n",
       "      <td>2018-07-09 14:27:52</td>\n",
       "      <td>0.991944</td>\n",
       "      <td>55.699516</td>\n",
       "      <td>12.587832</td>\n",
       "      <td>55.699516</td>\n",
       "      <td>12.587832</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601642</th>\n",
       "      <td>WBA1R5106J7B13384</td>\n",
       "      <td>2018-07-09 14:27:57</td>\n",
       "      <td>1.195000</td>\n",
       "      <td>55.662167</td>\n",
       "      <td>12.608710</td>\n",
       "      <td>55.662167</td>\n",
       "      <td>12.608710</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601643</th>\n",
       "      <td>WBA1R5103J7B13326</td>\n",
       "      <td>2018-07-09 14:29:12</td>\n",
       "      <td>1.438611</td>\n",
       "      <td>55.702984</td>\n",
       "      <td>12.556884</td>\n",
       "      <td>55.702984</td>\n",
       "      <td>12.556884</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401721</th>\n",
       "      <td>WBY8P2105K7D77234</td>\n",
       "      <td>2019-12-31 23:37:12</td>\n",
       "      <td>0.800556</td>\n",
       "      <td>55.672062</td>\n",
       "      <td>12.489302</td>\n",
       "      <td>55.672062</td>\n",
       "      <td>12.489302</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401722</th>\n",
       "      <td>WBY8P2100K7D93129</td>\n",
       "      <td>2019-12-31 23:40:15</td>\n",
       "      <td>4.764167</td>\n",
       "      <td>55.708767</td>\n",
       "      <td>12.530076</td>\n",
       "      <td>55.708767</td>\n",
       "      <td>12.530076</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401723</th>\n",
       "      <td>WBY8P2102K7E72639</td>\n",
       "      <td>2019-12-31 23:40:32</td>\n",
       "      <td>5.254167</td>\n",
       "      <td>55.696590</td>\n",
       "      <td>12.588531</td>\n",
       "      <td>55.696590</td>\n",
       "      <td>12.588531</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401724</th>\n",
       "      <td>WBY8P2102K7D70287</td>\n",
       "      <td>2019-12-31 23:41:09</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>55.691269</td>\n",
       "      <td>12.572398</td>\n",
       "      <td>55.691269</td>\n",
       "      <td>12.572398</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401725</th>\n",
       "      <td>WMWXU7106KTM90937</td>\n",
       "      <td>2019-12-31 23:51:31</td>\n",
       "      <td>0.658889</td>\n",
       "      <td>55.657730</td>\n",
       "      <td>12.558659</td>\n",
       "      <td>55.657730</td>\n",
       "      <td>12.558659</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800087 rows × 1044 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       car                time  time_to_reservation  \\\n",
       "601639   WBA1R5105J7B14249 2018-07-09 14:27:31             6.179444   \n",
       "601640   WBY1Z21040V307970 2018-07-09 14:27:37             3.777778   \n",
       "601641   WMWXR3102KTK68969 2018-07-09 14:27:52             0.991944   \n",
       "601642   WBA1R5106J7B13384 2018-07-09 14:27:57             1.195000   \n",
       "601643   WBA1R5103J7B13326 2018-07-09 14:29:12             1.438611   \n",
       "...                    ...                 ...                  ...   \n",
       "3401721  WBY8P2105K7D77234 2019-12-31 23:37:12             0.800556   \n",
       "3401722  WBY8P2100K7D93129 2019-12-31 23:40:15             4.764167   \n",
       "3401723  WBY8P2102K7E72639 2019-12-31 23:40:32             5.254167   \n",
       "3401724  WBY8P2102K7D70287 2019-12-31 23:41:09             0.226667   \n",
       "3401725  WMWXU7106KTM90937 2019-12-31 23:51:31             0.658889   \n",
       "\n",
       "         park_location_lat  park_location_long  leave_location_lat  \\\n",
       "601639           55.770130           12.518211           55.770130   \n",
       "601640           55.674522           12.559719           55.674522   \n",
       "601641           55.699516           12.587832           55.699516   \n",
       "601642           55.662167           12.608710           55.662167   \n",
       "601643           55.702984           12.556884           55.702984   \n",
       "...                    ...                 ...                 ...   \n",
       "3401721          55.672062           12.489302           55.672062   \n",
       "3401722          55.708767           12.530076           55.708767   \n",
       "3401723          55.696590           12.588531           55.696590   \n",
       "3401724          55.691269           12.572398           55.691269   \n",
       "3401725          55.657730           12.558659           55.657730   \n",
       "\n",
       "         leave_location_long  park_fuel  leave_fuel  moved  ...  lz_370133  \\\n",
       "601639             12.518211         96          96    0.0  ...          0   \n",
       "601640             12.559719         35          35    0.0  ...          0   \n",
       "601641             12.587832         39          39    0.0  ...          0   \n",
       "601642             12.608710         67          67    0.0  ...          0   \n",
       "601643             12.556884         42          42    0.0  ...          0   \n",
       "...                      ...        ...         ...    ...  ...        ...   \n",
       "3401721            12.489302         16          16    0.0  ...          0   \n",
       "3401722            12.530076         58          58    0.0  ...          0   \n",
       "3401723            12.588531         50          50    0.0  ...          0   \n",
       "3401724            12.572398         46          46    0.0  ...          0   \n",
       "3401725            12.558659         80          80    0.0  ...          0   \n",
       "\n",
       "         lz_376124  lz_461123  lz_561133  lz_730313  lz_751116  eng_118I  \\\n",
       "601639           0          0          0          0          0         1   \n",
       "601640           0          0          0          0          0         0   \n",
       "601641           0          0          0          0          0         0   \n",
       "601642           0          0          0          0          0         1   \n",
       "601643           0          0          0          0          0         1   \n",
       "...            ...        ...        ...        ...        ...       ...   \n",
       "3401721          0          0          0          0          0         0   \n",
       "3401722          0          0          0          0          0         0   \n",
       "3401723          0          0          0          0          0         0   \n",
       "3401724          0          0          0          0          0         0   \n",
       "3401725          0          0          0          0          0         0   \n",
       "\n",
       "         eng_COOPER  eng_I3  eng_X1  \n",
       "601639            0       0       0  \n",
       "601640            0       1       0  \n",
       "601641            1       0       0  \n",
       "601642            0       0       0  \n",
       "601643            0       0       0  \n",
       "...             ...     ...     ...  \n",
       "3401721           0       1       0  \n",
       "3401722           0       1       0  \n",
       "3401723           0       1       0  \n",
       "3401724           0       1       0  \n",
       "3401725           1       0       0  \n",
       "\n",
       "[2800087 rows x 1044 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5509f31e2044e4d39f528bdd5e1bbe95ee9581822c64151f31115901a677525b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('GNN_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
